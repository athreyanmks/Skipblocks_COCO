{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X3M86dgIWjeK"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision.transforms as tvt\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "from scipy.stats import wasserstein_distance\n",
        "import os\n",
        "import random\n",
        "from torch.utils.data import DataLoader\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "import json\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import google.colab.auth\n",
        "google.colab.auth.authenticate_user()\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "class COCO_mod ( torch . utils . data . Dataset ):\n",
        "\n",
        "    def __init__ ( self , root, class_labels ):\n",
        "        super () . __init__ ()\n",
        "        self.root = root\n",
        "        self.datapoints = os.listdir(root)\n",
        "        self.size = len([name for name in self.datapoints])\n",
        "        self.class_labels = class_labels\n",
        "        print(\"Dataset initalized\")\n",
        "\n",
        "    def __len__ (self):\n",
        "        return self.size\n",
        "\n",
        "    def __getitem__ ( self , index ):\n",
        "        item = Image.open(self.root + self.datapoints[index%self.size]).convert(\"RGB\")\n",
        "        name = self.datapoints[index%self.size].split('.')[0]\n",
        "        name = name.split(' ')[0]\n",
        "        if self.class_labels[name] == 4:\n",
        "            return_label = torch.FloatTensor([1,0,0,0,0])\n",
        "        elif self.class_labels[name] == 9:\n",
        "            return_label = torch.FloatTensor([0,1,0,0,0])\n",
        "        elif self.class_labels[name] == 18:\n",
        "            return_label = torch.FloatTensor([0,0,1,0,0])\n",
        "        elif self.class_labels[name] == 61:\n",
        "            return_label = torch.FloatTensor([0,0,0,1,0])\n",
        "        elif self.class_labels[name] == 63:\n",
        "            return_label = torch.FloatTensor([0,0,0,0,1])\n",
        "        # [4, 9, 18, 61, 63]\n",
        "        return self.tensorify(item), return_label\n",
        "\n",
        "    def tensorify(self,image):\n",
        "        augmenter = tvt.Compose([\n",
        "            tvt.ToTensor(),\n",
        "            tvt.CenterCrop([64,64])\n",
        "        ])\n",
        "        return augmenter(image)\n",
        "\n",
        "val_root = \"/content/drive/My Drive/compressed/val/\"\n",
        "train_root = \"/content/drive/My Drive/compressed/train/\"\n",
        "f = open('/content/drive/My Drive/image_lists.json')\n",
        "class_labels = json.load(f)\n",
        "\n",
        "my_val_dataset = COCO_mod(val_root,class_labels[\"val\"])\n",
        "length_val = len(my_val_dataset)\n",
        "# randomList = [random.randint(0,length_val) for _ in range(1000)]\n",
        "# val_dataset = [my_val_dataset.__getitem__(i) for i in range(length_val)]\n",
        "\n",
        "my_train_dataset = COCO_mod(train_root,class_labels[\"train\"])\n",
        "length_train = len(my_train_dataset)\n",
        "# randomList = [random.randint(0,length_train) for _ in range(1000)]\n",
        "# train_dataset = [my_train_dataset.__getitem__(i) for i in range(length_train)]\n",
        "print(\"Dataset done\")\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4FVDegwYBmYs",
        "outputId": "2dd1e79c-13c6-4fa1-c29d-0c60eb513b3f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Dataset initalized\n",
            "Dataset initalized\n",
            "Dataset done\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "val_dataloader = DataLoader ( my_val_dataset , batch_size = 8,shuffle = True )\n",
        "\n",
        "train_dataloader = DataLoader ( my_train_dataset , batch_size = 8,shuffle = True )\n",
        "print(\"Dataloader done\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KM_X0QJn8zEo",
        "outputId": "57386fbd-cf3c-4744-d158-a7190b50a382"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataloader done\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class SkipBlock(nn.Module):\n",
        "            \"\"\"\n",
        "            Class Path:   DLStudio  ->  SkipConnections  ->  SkipBlock\n",
        "            \"\"\"\n",
        "            def __init__(self, in_ch, out_ch, downsample=False, skip_connections=True):\n",
        "                super(SkipBlock, self).__init__()\n",
        "                self.downsample = downsample\n",
        "                self.skip_connections = skip_connections\n",
        "                self.in_ch = in_ch\n",
        "                self.out_ch = out_ch\n",
        "                self.convo1 = nn.Conv2d(in_ch, out_ch, 3, stride=1, padding=1)\n",
        "                self.convo2 = nn.Conv2d(in_ch, out_ch, 3, stride=1, padding=1)\n",
        "                self.bn1 = nn.BatchNorm2d(out_ch)\n",
        "                self.bn2 = nn.BatchNorm2d(out_ch)\n",
        "                if downsample:\n",
        "                    ##  Setting stride to 2 and kernel_size to 1 amounts to retaining every\n",
        "                    ##  other pixel in the image --- which halves the size of the image:\n",
        "                    self.downsampler = nn.Conv2d(in_ch, out_ch, 1, stride=2)\n",
        "\n",
        "            def forward(self, x):\n",
        "                identity = x\n",
        "                out = self.convo1(x)\n",
        "                out = self.bn1(out)\n",
        "                out = nn.functional.relu(out)\n",
        "                if self.in_ch == self.out_ch:\n",
        "                    out = self.convo2(out)\n",
        "                    out = self.bn2(out)\n",
        "                    out = nn.functional.relu(out)\n",
        "                # if self.downsample:\n",
        "                #     out = self.downsampler(out)\n",
        "                #     identity = self.downsampler(identity)\n",
        "                if self.skip_connections:\n",
        "                    if self.in_ch == self.out_ch:\n",
        "#                        out += identity\n",
        "                        out = out + identity\n",
        "                    else:\n",
        "                        ## To understand the following assignments, recall that the data has the\n",
        "                        ## shape [B,C,H,W]. So it is the second axis that corresponds to the channels\n",
        "                       out[:,:self.in_ch,:,:] += identity\n",
        "                       out[:,self.in_ch:,:,:] += identity\n",
        "                        # out = out + torch.cat((identity, identity), dim=1)\n",
        "                return nn.functional.relu(out)"
      ],
      "metadata": {
        "id": "dv7CAhQKBmC7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BMEnet2(nn.Module):\n",
        "    \"\"\"\n",
        "    Class Path:   DLStudio  ->  SkipConnections  ->  BMEnet\n",
        "    \"\"\"\n",
        "    def __init__(self, skip_connections=True, depth=20, channel_size=32):\n",
        "        super(BMEnet2, self).__init__()\n",
        "        self.depth = depth\n",
        "        self.first = SkipBlock(3, channel_size,skip_connections=False, downsample=False)\n",
        "        self.pool1 = nn.MaxPool2d(2, 2)\n",
        "        self.multiLayer1 = nn.ModuleList([SkipBlock(channel_size, channel_size, skip_connections=skip_connections, downsample=False) for i in range(0,self.depth,2)])\n",
        "        # for i in range(0,self.depth,2):\n",
        "        #     self.multiLayer1.append(SkipBlock(64, 64, skip_connections=skip_connections))\n",
        "\n",
        "        self.pool2 = nn.MaxPool2d(2,2)\n",
        "        self.multiLayer2 = nn.ModuleList([SkipBlock(channel_size, channel_size, skip_connections=skip_connections, downsample=False) for i in range(0,self.depth,2)])\n",
        "        # for i in range(0,self.depth,2):\n",
        "        #     self.multiLayer2.append(SkipBlock(64, 64, skip_connections=skip_connections))\n",
        "        # self.skip64ds = DLStudio.SkipConnections.SkipBlock(64, 64,\n",
        "        #                             downsample=True, skip_connections=skip_connections)\n",
        "        # self.skip64to128 = DLStudio.SkipConnections.SkipBlock(64, 128,\n",
        "        #                                             skip_connections=skip_connections )\n",
        "        # self.skip128_arr = nn.ModuleList()\n",
        "        # for i in range(self.depth):\n",
        "        #     self.skip128_arr.append(DLStudio.SkipConnections.SkipBlock(128, 128,\n",
        "        #                                             skip_connections=skip_connections))\n",
        "        # self.skip128ds = DLStudio.SkipConnections.SkipBlock(128,128,\n",
        "        #                             downsample=True, skip_connections=skip_connections)\n",
        "        ##  The following declaration is predicated on the assumption that the number of\n",
        "        ##  output nodes (CxHxW) from the final convo layer exactly 2048 for each\n",
        "        ##  input image.  Depending on the size of the input image, this places a constraint\n",
        "        ##  on how many downsampling instances of SkipBlock you can call in a network.\n",
        "        self.fc1 =  nn.Linear(channel_size*16*16, 1000)\n",
        "        self.fc2 =  nn.Linear(1000, 5)\n",
        "        self.sm = nn.Softmax(dim=0)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool1(nn.functional.relu(self.first(x)))\n",
        "        for layer in self.multiLayer1:\n",
        "            x = nn.functional.relu(layer(x))\n",
        "        x = self.pool2(x)\n",
        "        for layer in self.multiLayer2:\n",
        "            x = nn.functional.relu(layer(x))\n",
        "        # for i,skip64 in enumerate(self.skip64_arr[:self.depth//4]):\n",
        "        #     x = skip64(x)\n",
        "        # x = self.skip64ds(x)\n",
        "        # for i,skip64 in enumerate(self.skip64_arr[self.depth//4:]):\n",
        "        #     x = skip64(x)\n",
        "        # x = self.skip64ds(x)\n",
        "        # x = self.skip64to128(x)\n",
        "        # for i,skip128 in enumerate(self.skip128_arr[:self.depth//4]):\n",
        "        #     x = skip128(x)\n",
        "        # for i,skip128 in enumerate(self.skip128_arr[self.depth//4:]):\n",
        "        #     x = skip128(x)\n",
        "        ## See the comment block above the \"self.fc1\" declaration in the constructor code.\n",
        "        x  =  x.view( x.shape[0], - 1 )\n",
        "        x = nn.functional.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        # x = self.sm(x)\n",
        "        return x\n",
        "\n"
      ],
      "metadata": {
        "id": "F1H_QLV8jHul"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BMEnet(nn.Module):\n",
        "    \"\"\"\n",
        "    Class Path:   DLStudio  ->  SkipConnections  ->  BMEnet\n",
        "    \"\"\"\n",
        "    def __init__(self, skip_connections=True, depth=32):\n",
        "        super(BMEnet, self).__init__()\n",
        "        if depth not in [8, 16, 32, 64]:\n",
        "            sys.exit(\"BMEnet has been tested for depth for only 8, 16, 32, and 64\")\n",
        "        self.depth = depth // 8\n",
        "        self.conv = nn.Conv2d(3, 64, 3, padding=1)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.skip64_arr = nn.ModuleList()\n",
        "        for i in range(self.depth):\n",
        "            self.skip64_arr.append(SkipBlock(64, 64,\n",
        "                                                    skip_connections=skip_connections))\n",
        "        self.skip64ds = SkipBlock(64, 64,\n",
        "                                    downsample=True, skip_connections=skip_connections)\n",
        "        self.skip64to128 = SkipBlock(64, 128,\n",
        "                                                    skip_connections=skip_connections )\n",
        "        self.skip128_arr = nn.ModuleList()\n",
        "        for i in range(self.depth):\n",
        "            self.skip128_arr.append(SkipBlock(128, 128,\n",
        "                                                    skip_connections=skip_connections))\n",
        "        self.skip128ds = SkipBlock(128,128,\n",
        "                                    downsample=True, skip_connections=skip_connections)\n",
        "        ##  The following declaration is predicated on the assumption that the number of\n",
        "        ##  output nodes (CxHxW) from the final convo layer exactly 2048 for each\n",
        "        ##  input image.  Depending on the size of the input image, this places a constraint\n",
        "        ##  on how many downsampling instances of SkipBlock you can call in a network.\n",
        "        self.fc1 =  nn.Linear(65536, 1000)\n",
        "        self.fc2 =  nn.Linear(1000, 5)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(nn.functional.relu(self.conv(x)))\n",
        "        for i,skip64 in enumerate(self.skip64_arr[:self.depth//4]):\n",
        "            x = skip64(x)\n",
        "        x = self.skip64ds(x)\n",
        "        for i,skip64 in enumerate(self.skip64_arr[self.depth//4:]):\n",
        "            x = skip64(x)\n",
        "        x = self.skip64ds(x)\n",
        "        # x = self.skip64to128(x)\n",
        "        # for i,skip128 in enumerate(self.skip128_arr[:self.depth//4]):\n",
        "        #     x = skip128(x)\n",
        "        # for i,skip128 in enumerate(self.skip128_arr[self.depth//4:]):\n",
        "        #     x = skip128(x)\n",
        "        ## See the comment block above the \"self.fc1\" declaration in the constructor code.\n",
        "        x  =  x.view( x.shape[0], - 1 )\n",
        "        x = nn.functional.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "JtzXc60jRWvG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_training(net, train_data_loader, device, learning_rate):\n",
        "    net = net.to( device )\n",
        "    criterion = torch.nn.CrossEntropyLoss ()\n",
        "    optimizer = torch.optim.Adam (\n",
        "    net.parameters () , lr=learning_rate , betas =(0.9, 0.99))\n",
        "    epochs = 30\n",
        "    loss_tracking = []\n",
        "    for epoch in range ( epochs ):\n",
        "        running_loss = 0.0\n",
        "        for i , data in enumerate ( train_data_loader ):\n",
        "            inputs , labels = data\n",
        "            # print()\n",
        "            inputs = inputs.to( device )\n",
        "            labels = labels.to( device )\n",
        "            optimizer . zero_grad ()\n",
        "            outputs = net ( inputs )\n",
        "            loss = criterion ( outputs , labels )\n",
        "            loss . backward ()\n",
        "\n",
        "            optimizer . step ()\n",
        "            running_loss += loss . item ()\n",
        "            if (i+1 ) % 500 == 0:\n",
        "                print (\"[ epoch : %d, batch : %5d] loss : %.3f\" \\\n",
        "                 % ( epoch + 1 , i + 1 , running_loss / 100 ) )\n",
        "            if(i % 100 == 0):\n",
        "                loss_tracking.append(running_loss/100)\n",
        "                running_loss = 0.0\n",
        "    return loss_tracking\n",
        "\n",
        "def run_code_for_testing(net, test_data_loader, device):\n",
        "    net = net.eval()\n",
        "    net = net.to(device)\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    confusion_matrix = torch.zeros(5, 5)\n",
        "    class_correct = [0] * 5\n",
        "    class_total = [0] * 5\n",
        "    with torch.no_grad():\n",
        "        for i,data in enumerate(test_data_loader):\n",
        "            ##  data is set to the images and the labels for one batch at a time:\n",
        "            images, labels = data\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "            if i % 1000 == 999:\n",
        "                print(\"\\n\\n[i=%d:] Ground Truth:     \" % (i+1) + ' '.join('%5s' % self.class_labels[labels[j]]\n",
        "                                                               for j in range(self.batch_size)))\n",
        "            outputs = net(images)\n",
        "            predicted = outputs\n",
        "            for label,prediction in zip(labels,predicted):\n",
        "                    # print(prediction)\n",
        "                    confusion_matrix[torch.argmax(label)][torch.argmax(prediction)] += 1\n",
        "                    correct += 1 if torch.argmax(label) == torch.argmax(prediction) else 0\n",
        "            total += labels.size(0)\n",
        "            if (i%100 == 99):\n",
        "                print(i)\n",
        "\n",
        "    print(\"\\n\\n\\nOverall accuracy of the network on the test images: %d %%\" % (100 * correct / float(total)))\n",
        "    print(\"\\n\\nDisplaying the confusion matrix:\\n\")\n",
        "\n",
        "    print(confusion_matrix)\n",
        "    return confusion_matrix"
      ],
      "metadata": {
        "id": "Mkq6djNOE0As"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "xSs1wvpoGfM4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = 2e-4\n",
        "BIGNet1 = BMEnet2(skip_connections=True, depth=20, channel_size=128)\n",
        "bignet_loss = run_training(BIGNet1, train_dataloader, device, learning_rate)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "id": "SDxeSQzPGGpP",
        "outputId": "1a8ef5d0-a005-423f-e9ac-135e1cb5c4f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-4f48f3f07fcd>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mlearning_rate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2e-4\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mBIGNet1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBMEnet2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mskip_connections\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdepth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchannel_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mbignet_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBIGNet1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-9-46de72e355a6>\u001b[0m in \u001b[0;36mrun_training\u001b[0;34m(net, train_data_loader, device, learning_rate)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m \u001b[0;34m(\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mrunning_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m \u001b[0;34m(\u001b[0m \u001b[0mtrain_data_loader\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m             \u001b[0minputs\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0;31m# print()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    628\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 630\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    631\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    672\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    673\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 674\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    675\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    676\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-4-89dd224ac22e>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m \u001b[0;34m(\u001b[0m \u001b[0mself\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mitem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatapoints\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"RGB\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatapoints\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode, formats)\u001b[0m\n\u001b[1;32m   3234\u001b[0m         \u001b[0mexclusive_fp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3236\u001b[0;31m     \u001b[0mprefix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3237\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3238\u001b[0m     \u001b[0mpreinit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(BIGNet1.state_dict(), \"/content/drive/My Drive/ece60146/HW5/models/BIGnet1_final2.pth\")\n",
        "\n",
        "with open('/content/drive/My Drive/ece60146/HW5/bignet1_final2_network_losses.json', 'w') as f:\n",
        "    json.dump(bignet_loss, f)"
      ],
      "metadata": {
        "id": "NDUCqgqDCFSo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bignet_confusion = run_code_for_testing(BIGNet1, val_dataloader, device)\n",
        "# bignet_confusion = run_code_for_testing(BIGNet, train_dataloader, device)"
      ],
      "metadata": {
        "id": "hAKjODlsGfe3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = 3e-4\n",
        "BIGNet2 = BMEnet2(skip_connections=True, depth=20, channel_size=64)\n",
        "bignet2_loss = run_training(BIGNet2, train_dataloader, device, learning_rate)"
      ],
      "metadata": {
        "id": "wej2xO6TvVDX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(BIGNet2.state_dict(), \"/content/drive/My Drive/ece60146/HW5/models/BIGnet2_final2.pth\")\n",
        "\n",
        "with open('/content/drive/My Drive/ece60146/HW5/bignet2_final2_network_losses.json', 'w') as f:\n",
        "    json.dump(bignet2_loss, f)"
      ],
      "metadata": {
        "id": "t0Lj3nq-vUvD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bignet2_confusion = run_code_for_testing(BIGNet2, val_dataloader, device)"
      ],
      "metadata": {
        "id": "uTEdY0U957eU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# torch.save(BIGNet2.state_dict(), \"/content/drive/My Drive/ece60146/HW5/models/BIGnet2.pth\")\n",
        "\n",
        "# with open('/content/drive/My Drive/ece60146/HW5/bignet2_network_losses.json', 'w') as f:\n",
        "#     json.dump(bignet_loss, f)"
      ],
      "metadata": {
        "id": "ALw3-DAg8jAb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}