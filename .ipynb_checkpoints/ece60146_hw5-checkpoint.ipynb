{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "X3M86dgIWjeK"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.transforms as tvt\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from scipy.stats import wasserstein_distance\n",
    "import os\n",
    "import random\n",
    "from torch.utils.data import DataLoader\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4FVDegwYBmYs",
    "outputId": "2dd1e79c-13c6-4fa1-c29d-0c60eb513b3f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset initalized\n",
      "Dataset initalized\n",
      "Dataset done\n"
     ]
    }
   ],
   "source": [
    "# from google.colab import drive\n",
    "# import google.colab.auth\n",
    "# google.colab.auth.authenticate_user()\n",
    "# drive.mount('/content/drive')\n",
    "\n",
    "class COCO_mod ( torch . utils . data . Dataset ):\n",
    "\n",
    "    def __init__ ( self , root, class_labels ):\n",
    "        super () . __init__ ()\n",
    "        self.root = root\n",
    "        self.datapoints = os.listdir(root)\n",
    "        self.size = len([name for name in self.datapoints])\n",
    "        self.class_labels = class_labels\n",
    "        print(\"Dataset initalized\")\n",
    "\n",
    "    def __len__ (self):\n",
    "        return self.size\n",
    "\n",
    "    def __getitem__ ( self , index ):\n",
    "        item = Image.open(self.root + self.datapoints[index%self.size]).convert(\"RGB\")\n",
    "        name = self.datapoints[index%self.size].split('.')[0]\n",
    "        name = name.split(' ')[0]\n",
    "        if self.class_labels[name] == 4:\n",
    "            return_label = torch.FloatTensor([1,0,0,0,0])\n",
    "        elif self.class_labels[name] == 9:\n",
    "            return_label = torch.FloatTensor([0,1,0,0,0])\n",
    "        elif self.class_labels[name] == 18:\n",
    "            return_label = torch.FloatTensor([0,0,1,0,0])\n",
    "        elif self.class_labels[name] == 61:\n",
    "            return_label = torch.FloatTensor([0,0,0,1,0])\n",
    "        elif self.class_labels[name] == 63:\n",
    "            return_label = torch.FloatTensor([0,0,0,0,1])\n",
    "        # [4, 9, 18, 61, 63]\n",
    "        return self.tensorify(item), return_label\n",
    "\n",
    "    def tensorify(self,image):\n",
    "        augmenter = tvt.Compose([\n",
    "            tvt.ToTensor(),\n",
    "            tvt.CenterCrop([64,64])\n",
    "        ])\n",
    "        return augmenter(image)\n",
    "\n",
    "val_root = \"compressed/val/\"\n",
    "train_root = \"compressed/train/\"\n",
    "f = open('image_lists.json')\n",
    "class_labels = json.load(f)\n",
    "\n",
    "my_val_dataset = COCO_mod(val_root,class_labels[\"val\"])\n",
    "length_val = len(my_val_dataset)\n",
    "# randomList = [random.randint(0,length_val) for _ in range(1000)]\n",
    "# val_dataset = [my_val_dataset.__getitem__(i) for i in range(length_val)]\n",
    "\n",
    "my_train_dataset = COCO_mod(train_root,class_labels[\"train\"])\n",
    "length_train = len(my_train_dataset)\n",
    "# randomList = [random.randint(0,length_train) for _ in range(1000)]\n",
    "# train_dataset = [my_train_dataset.__getitem__(i) for i in range(length_train)]\n",
    "print(\"Dataset done\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KM_X0QJn8zEo",
    "outputId": "57386fbd-cf3c-4744-d158-a7190b50a382"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataloader done\n"
     ]
    }
   ],
   "source": [
    "val_dataloader = DataLoader ( my_val_dataset , batch_size = 8,shuffle = True )\n",
    "\n",
    "train_dataloader = DataLoader ( my_train_dataset , batch_size = 8,shuffle = True )\n",
    "print(\"Dataloader done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "dv7CAhQKBmC7"
   },
   "outputs": [],
   "source": [
    "class SkipBlock(nn.Module):\n",
    "            \"\"\"\n",
    "            Class Path:   DLStudio  ->  SkipConnections  ->  SkipBlock\n",
    "            \"\"\"\n",
    "            def __init__(self, in_ch, out_ch, downsample=False, skip_connections=True):\n",
    "                super(SkipBlock, self).__init__()\n",
    "                self.downsample = downsample\n",
    "                self.skip_connections = skip_connections\n",
    "                self.in_ch = in_ch\n",
    "                self.out_ch = out_ch\n",
    "                self.convo1 = nn.Conv2d(in_ch, out_ch, 3, stride=1, padding=1)\n",
    "                self.convo2 = nn.Conv2d(in_ch, out_ch, 3, stride=1, padding=1)\n",
    "                self.bn1 = nn.BatchNorm2d(out_ch)\n",
    "                self.bn2 = nn.BatchNorm2d(out_ch)\n",
    "                if downsample:\n",
    "                    ##  Setting stride to 2 and kernel_size to 1 amounts to retaining every\n",
    "                    ##  other pixel in the image --- which halves the size of the image:\n",
    "                    self.downsampler = nn.Conv2d(in_ch, out_ch, 1, stride=2)\n",
    "\n",
    "            def forward(self, x):\n",
    "                identity = x\n",
    "                out = self.convo1(x)\n",
    "                out = self.bn1(out)\n",
    "                out = nn.functional.relu(out)\n",
    "                if self.in_ch == self.out_ch:\n",
    "                    out = self.convo2(out)\n",
    "                    out = self.bn2(out)\n",
    "                    out = nn.functional.relu(out)\n",
    "                # if self.downsample:\n",
    "                #     out = self.downsampler(out)\n",
    "                #     identity = self.downsampler(identity)\n",
    "                if self.skip_connections:\n",
    "                    if self.in_ch == self.out_ch:\n",
    "#                        out += identity\n",
    "                        out = out + identity\n",
    "                    else:\n",
    "                        ## To understand the following assignments, recall that the data has the\n",
    "                        ## shape [B,C,H,W]. So it is the second axis that corresponds to the channels\n",
    "                       out[:,:self.in_ch,:,:] += identity\n",
    "                       out[:,self.in_ch:,:,:] += identity\n",
    "                        # out = out + torch.cat((identity, identity), dim=1)\n",
    "                return nn.functional.relu(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "F1H_QLV8jHul"
   },
   "outputs": [],
   "source": [
    "class BMEnet2(nn.Module):\n",
    "    \"\"\"\n",
    "    Class Path:   DLStudio  ->  SkipConnections  ->  BMEnet\n",
    "    \"\"\"\n",
    "    def __init__(self, skip_connections=True, depth=20, channel_size=32):\n",
    "        super(BMEnet2, self).__init__()\n",
    "        self.depth = depth\n",
    "        self.first = SkipBlock(3, channel_size,skip_connections=False, downsample=False)\n",
    "        self.pool1 = nn.MaxPool2d(2, 2)\n",
    "        self.multiLayer1 = nn.ModuleList([SkipBlock(channel_size, channel_size, skip_connections=skip_connections, downsample=False) for i in range(0,self.depth,2)])\n",
    "        # for i in range(0,self.depth,2):\n",
    "        #     self.multiLayer1.append(SkipBlock(64, 64, skip_connections=skip_connections))\n",
    "\n",
    "        self.pool2 = nn.MaxPool2d(2,2)\n",
    "        self.multiLayer2 = nn.ModuleList([SkipBlock(channel_size, channel_size, skip_connections=skip_connections, downsample=False) for i in range(0,self.depth,2)])\n",
    "        # for i in range(0,self.depth,2):\n",
    "        #     self.multiLayer2.append(SkipBlock(64, 64, skip_connections=skip_connections))\n",
    "        # self.skip64ds = DLStudio.SkipConnections.SkipBlock(64, 64,\n",
    "        #                             downsample=True, skip_connections=skip_connections)\n",
    "        # self.skip64to128 = DLStudio.SkipConnections.SkipBlock(64, 128,\n",
    "        #                                             skip_connections=skip_connections )\n",
    "        # self.skip128_arr = nn.ModuleList()\n",
    "        # for i in range(self.depth):\n",
    "        #     self.skip128_arr.append(DLStudio.SkipConnections.SkipBlock(128, 128,\n",
    "        #                                             skip_connections=skip_connections))\n",
    "        # self.skip128ds = DLStudio.SkipConnections.SkipBlock(128,128,\n",
    "        #                             downsample=True, skip_connections=skip_connections)\n",
    "        ##  The following declaration is predicated on the assumption that the number of\n",
    "        ##  output nodes (CxHxW) from the final convo layer exactly 2048 for each\n",
    "        ##  input image.  Depending on the size of the input image, this places a constraint\n",
    "        ##  on how many downsampling instances of SkipBlock you can call in a network.\n",
    "        self.fc1 =  nn.Linear(channel_size*16*16, 1000)\n",
    "        self.fc2 =  nn.Linear(1000, 5)\n",
    "        self.sm = nn.Softmax(dim=0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool1(nn.functional.relu(self.first(x)))\n",
    "        for layer in self.multiLayer1:\n",
    "            x = nn.functional.relu(layer(x))\n",
    "        x = self.pool2(x)\n",
    "        for layer in self.multiLayer2:\n",
    "            x = nn.functional.relu(layer(x))\n",
    "        # for i,skip64 in enumerate(self.skip64_arr[:self.depth//4]):\n",
    "        #     x = skip64(x)\n",
    "        # x = self.skip64ds(x)\n",
    "        # for i,skip64 in enumerate(self.skip64_arr[self.depth//4:]):\n",
    "        #     x = skip64(x)\n",
    "        # x = self.skip64ds(x)\n",
    "        # x = self.skip64to128(x)\n",
    "        # for i,skip128 in enumerate(self.skip128_arr[:self.depth//4]):\n",
    "        #     x = skip128(x)\n",
    "        # for i,skip128 in enumerate(self.skip128_arr[self.depth//4:]):\n",
    "        #     x = skip128(x)\n",
    "        ## See the comment block above the \"self.fc1\" declaration in the constructor code.\n",
    "        x  =  x.view( x.shape[0], - 1 )\n",
    "        x = nn.functional.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        # x = self.sm(x)\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "JtzXc60jRWvG"
   },
   "outputs": [],
   "source": [
    "class BMEnet(nn.Module):\n",
    "    \"\"\"\n",
    "    Class Path:   DLStudio  ->  SkipConnections  ->  BMEnet\n",
    "    \"\"\"\n",
    "    def __init__(self, skip_connections=True, depth=32):\n",
    "        super(BMEnet, self).__init__()\n",
    "        if depth not in [8, 16, 32, 64]:\n",
    "            sys.exit(\"BMEnet has been tested for depth for only 8, 16, 32, and 64\")\n",
    "        self.depth = depth // 8\n",
    "        self.conv = nn.Conv2d(3, 64, 3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.skip64_arr = nn.ModuleList()\n",
    "        for i in range(self.depth):\n",
    "            self.skip64_arr.append(SkipBlock(64, 64,\n",
    "                                                    skip_connections=skip_connections))\n",
    "        self.skip64ds = SkipBlock(64, 64,\n",
    "                                    downsample=True, skip_connections=skip_connections)\n",
    "        self.skip64to128 = SkipBlock(64, 128,\n",
    "                                                    skip_connections=skip_connections )\n",
    "        self.skip128_arr = nn.ModuleList()\n",
    "        for i in range(self.depth):\n",
    "            self.skip128_arr.append(SkipBlock(128, 128,\n",
    "                                                    skip_connections=skip_connections))\n",
    "        self.skip128ds = SkipBlock(128,128,\n",
    "                                    downsample=True, skip_connections=skip_connections)\n",
    "        ##  The following declaration is predicated on the assumption that the number of\n",
    "        ##  output nodes (CxHxW) from the final convo layer exactly 2048 for each\n",
    "        ##  input image.  Depending on the size of the input image, this places a constraint\n",
    "        ##  on how many downsampling instances of SkipBlock you can call in a network.\n",
    "        self.fc1 =  nn.Linear(65536, 1000)\n",
    "        self.fc2 =  nn.Linear(1000, 5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(nn.functional.relu(self.conv(x)))\n",
    "        for i,skip64 in enumerate(self.skip64_arr[:self.depth//4]):\n",
    "            x = skip64(x)\n",
    "        x = self.skip64ds(x)\n",
    "        for i,skip64 in enumerate(self.skip64_arr[self.depth//4:]):\n",
    "            x = skip64(x)\n",
    "        x = self.skip64ds(x)\n",
    "        # x = self.skip64to128(x)\n",
    "        # for i,skip128 in enumerate(self.skip128_arr[:self.depth//4]):\n",
    "        #     x = skip128(x)\n",
    "        # for i,skip128 in enumerate(self.skip128_arr[self.depth//4:]):\n",
    "        #     x = skip128(x)\n",
    "        ## See the comment block above the \"self.fc1\" declaration in the constructor code.\n",
    "        x  =  x.view( x.shape[0], - 1 )\n",
    "        x = nn.functional.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "Mkq6djNOE0As"
   },
   "outputs": [],
   "source": [
    "def run_training(net, train_data_loader, device, learning_rate):\n",
    "    net = net.to( device )\n",
    "    criterion = torch.nn.CrossEntropyLoss ()\n",
    "    optimizer = torch.optim.Adam (\n",
    "    net.parameters () , lr=learning_rate , betas =(0.9, 0.99))\n",
    "    epochs = 30\n",
    "    loss_tracking = []\n",
    "    for epoch in range ( epochs ):\n",
    "        running_loss = 0.0\n",
    "        for i , data in enumerate ( train_data_loader ):\n",
    "            inputs , labels = data\n",
    "            # print()\n",
    "            inputs = inputs.to( device )\n",
    "            labels = labels.to( device )\n",
    "            optimizer . zero_grad ()\n",
    "            outputs = net ( inputs )\n",
    "            loss = criterion ( outputs , labels )\n",
    "            loss . backward ()\n",
    "\n",
    "            optimizer . step ()\n",
    "            running_loss += loss . item ()\n",
    "            if (i+1 ) % 500 == 0:\n",
    "                print (\"[ epoch : %d, batch : %5d] loss : %.3f\" \\\n",
    "                 % ( epoch + 1 , i + 1 , running_loss / 100 ) )\n",
    "            if(i % 100 == 0):\n",
    "                loss_tracking.append(running_loss/100)\n",
    "                running_loss = 0.0\n",
    "    return loss_tracking\n",
    "\n",
    "def run_code_for_testing(net, test_data_loader, device):\n",
    "    net = net.eval()\n",
    "    net = net.to(device)\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    confusion_matrix = torch.zeros(5, 5)\n",
    "    class_correct = [0] * 5\n",
    "    class_total = [0] * 5\n",
    "    with torch.no_grad():\n",
    "        for i,data in enumerate(test_data_loader):\n",
    "            ##  data is set to the images and the labels for one batch at a time:\n",
    "            images, labels = data\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            if i % 1000 == 999:\n",
    "                print(\"\\n\\n[i=%d:] Ground Truth:     \" % (i+1) + ' '.join('%5s' % self.class_labels[labels[j]]\n",
    "                                                               for j in range(self.batch_size)))\n",
    "            outputs = net(images)\n",
    "            predicted = outputs\n",
    "            for label,prediction in zip(labels,predicted):\n",
    "                    # print(prediction)\n",
    "                    confusion_matrix[torch.argmax(label)][torch.argmax(prediction)] += 1\n",
    "                    correct += 1 if torch.argmax(label) == torch.argmax(prediction) else 0\n",
    "            total += labels.size(0)\n",
    "            if (i%100 == 99):\n",
    "                print(i)\n",
    "\n",
    "    print(\"\\n\\n\\nOverall accuracy of the network on the test images: %d %%\" % (100 * correct / float(total)))\n",
    "    print(\"\\n\\nDisplaying the confusion matrix:\\n\")\n",
    "\n",
    "    print(confusion_matrix)\n",
    "    return confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "xSs1wvpoGfM4"
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 321
    },
    "id": "SDxeSQzPGGpP",
    "outputId": "1a8ef5d0-a005-423f-e9ac-135e1cb5c4f9"
   },
   "outputs": [],
   "source": [
    "learning_rate = 2e-4\n",
    "BIGNet1 = BMEnet2(skip_connections=True, depth=20, channel_size=128)\n",
    "bignet_loss = run_training(BIGNet1, train_dataloader, device, learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NDUCqgqDCFSo"
   },
   "outputs": [],
   "source": [
    "torch.save(BIGNet1.state_dict(), \"/content/drive/My Drive/ece60146/HW5/models/BIGnet1_final.pth\")\n",
    "\n",
    "with open('/content/drive/My Drive/ece60146/HW5/bignet1_final2_network_losses.json', 'w') as f:\n",
    "    json.dump(bignet_loss, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hAKjODlsGfe3"
   },
   "outputs": [],
   "source": [
    "bignet_confusion = run_code_for_testing(BIGNet1, val_dataloader, device)\n",
    "# bignet_confusion = run_code_for_testing(BIGNet, train_dataloader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wej2xO6TvVDX"
   },
   "outputs": [],
   "source": [
    "learning_rate = 3e-4\n",
    "BIGNet2 = BMEnet2(skip_connections=True, depth=20, channel_size=64)\n",
    "bignet2_loss = run_training(BIGNet2, train_dataloader, device, learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "t0Lj3nq-vUvD"
   },
   "outputs": [],
   "source": [
    "torch.save(BIGNet2.state_dict(), \"/content/drive/My Drive/ece60146/HW5/models/BIGnet2_final.pth\")\n",
    "\n",
    "with open('/content/drive/My Drive/ece60146/HW5/bignet2_final2_network_losses.json', 'w') as f:\n",
    "    json.dump(bignet2_loss, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uTEdY0U957eU"
   },
   "outputs": [],
   "source": [
    "bignet2_confusion = run_code_for_testing(BIGNet2, val_dataloader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "ALw3-DAg8jAb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BIGNet1 = BMEnet2(skip_connections=True, depth=20, channel_size=64)\n",
    "BIGNet1.load_state_dict(torch.load('models/BIGnet1_final.pth',map_location=torch.device('cpu')))\n",
    "\n",
    "BIGNet2 = BMEnet2(skip_connections=True, depth=20, channel_size=64)\n",
    "BIGNet2.load_state_dict(torch.load('models/BIGnet2_final.pth',map_location=torch.device('cpu')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99\n"
     ]
    }
   ],
   "source": [
    "bignet_confusion = run_code_for_testing(BIGNet1, val_dataloader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bignet2_confusion = run_code_for_testing(BIGNet2, val_dataloader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "V100",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
